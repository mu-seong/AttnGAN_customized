{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from miscc.utils import mkdir_p\n",
    "from miscc.utils import build_super_images\n",
    "from miscc.losses import sent_loss, words_loss\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "\n",
    "from datasets import TextDataset\n",
    "from datasets import prepare_data\n",
    "\n",
    "from model import RNN_ENCODER, CNN_ENCODER\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "#import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import easydict\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = (os.path.abspath(os.path.join(os.path.realpath(\"__file__\"), './.')))\n",
    "sys.path.append(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def parse_args():\\n    parser = argparse.ArgumentParser(description='Train a DAMSM network')\\n    parser.add_argument('--cfg', dest='cfg_file',\\n                        help='optional config file',\\n                        default='cfg/DAMSM/bird.yml', type=str)\\n    parser.add_argument('--gpu', dest='gpu_id', type=int, default=0)\\n    parser.add_argument('--data_dir', dest='data_dir', type=str, default='')\\n    parser.add_argument('--manualSeed', type=int, help='manual seed')\\n    args = parser.parse_args()\\n    return args\\n    \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UPDATE_INTERVAL = 200\n",
    "\"\"\"def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train a DAMSM network')\n",
    "    parser.add_argument('--cfg', dest='cfg_file',\n",
    "                        help='optional config file',\n",
    "                        default='cfg/DAMSM/bird.yml', type=str)\n",
    "    parser.add_argument('--gpu', dest='gpu_id', type=int, default=0)\n",
    "    parser.add_argument('--data_dir', dest='data_dir', type=str, default='')\n",
    "    parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"cfg_file\": 'cfg/DAMSM/coco.yml',\n",
    "    \"gpu_id\": 0,\n",
    "    \"data_dir\": '../data/coco',\n",
    "    \"manualSeed\": 100\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, cnn_model, rnn_model, batch_size,\n",
    "          labels, optimizer, epoch, ixtoword, image_dir):\n",
    "    cnn_model.train()\n",
    "    rnn_model.train()\n",
    "    s_total_loss0 = 0\n",
    "    s_total_loss1 = 0\n",
    "    w_total_loss0 = 0\n",
    "    w_total_loss1 = 0\n",
    "    count = (epoch + 1) * len(dataloader)\n",
    "    # print(count)\n",
    "    start_time = time.time()\n",
    "    for step, data in enumerate(dataloader, 0):\n",
    "        # print('step', step)\n",
    "        rnn_model.zero_grad()\n",
    "        cnn_model.zero_grad()\n",
    "\n",
    "        imgs, captions, cap_lens, \\\n",
    "            class_ids, keys = prepare_data(data)\n",
    "\n",
    "\n",
    "        # words_features: batch_size x nef x 17 x 17\n",
    "        # sent_code: batch_size x nef\n",
    "        words_features, sent_code = cnn_model(imgs[-1])\n",
    "        # --> batch_size x nef x 17*17\n",
    "        nef, att_sze = words_features.size(1), words_features.size(2)\n",
    "        # words_features = words_features.view(batch_size, nef, -1)\n",
    "\n",
    "        hidden = rnn_model.init_hidden(batch_size)\n",
    "        # words_emb: batch_size x nef x seq_len\n",
    "        # sent_emb: batch_size x nef\n",
    "        words_emb, sent_emb = rnn_model(captions, cap_lens, hidden)\n",
    "\n",
    "        w_loss0, w_loss1, attn_maps = words_loss(words_features, words_emb, labels,\n",
    "                                                 cap_lens, class_ids, batch_size)\n",
    "        w_total_loss0 += w_loss0.data\n",
    "        w_total_loss1 += w_loss1.data\n",
    "        loss = w_loss0 + w_loss1\n",
    "\n",
    "        s_loss0, s_loss1 = \\\n",
    "            sent_loss(sent_code, sent_emb, labels, class_ids, batch_size)\n",
    "        loss += s_loss0 + s_loss1\n",
    "        s_total_loss0 += s_loss0.data\n",
    "        s_total_loss1 += s_loss1.data\n",
    "        #\n",
    "        loss.backward()\n",
    "        #\n",
    "        # `clip_grad_norm` helps prevent\n",
    "        # the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_norm(rnn_model.parameters(),\n",
    "                                      cfg.TRAIN.RNN_GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % UPDATE_INTERVAL == 0:\n",
    "            count = epoch * len(dataloader) + step\n",
    "\n",
    "            s_cur_loss0 = s_total_loss0 / UPDATE_INTERVAL\n",
    "            s_cur_loss1 = s_total_loss1 / UPDATE_INTERVAL\n",
    "\n",
    "            w_cur_loss0 = w_total_loss0 / UPDATE_INTERVAL\n",
    "            w_cur_loss1 = w_total_loss1 / UPDATE_INTERVAL\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '\n",
    "                  's_loss {:5.2f} {:5.2f} | '\n",
    "                  'w_loss {:5.2f} {:5.2f}'\n",
    "                  .format(epoch, step, len(dataloader),\n",
    "                          elapsed * 1000. / UPDATE_INTERVAL,\n",
    "                          s_cur_loss0, s_cur_loss1,\n",
    "                          w_cur_loss0, w_cur_loss1))\n",
    "            s_total_loss0 = 0\n",
    "            s_total_loss1 = 0\n",
    "            w_total_loss0 = 0\n",
    "            w_total_loss1 = 0\n",
    "            start_time = time.time()\n",
    "            # attention Maps\n",
    "            img_set, _ = \\\n",
    "                build_super_images(imgs[-1].cpu(), captions,\n",
    "                                   ixtoword, attn_maps, att_sze)\n",
    "            if img_set is not None:\n",
    "                im = Image.fromarray(img_set)\n",
    "                fullpath = '%s/attention_maps%d.png' % (image_dir, step)\n",
    "                im.save(fullpath)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, cnn_model, rnn_model, batch_size):\n",
    "    cnn_model.eval()\n",
    "    rnn_model.eval()\n",
    "    s_total_loss = 0\n",
    "    w_total_loss = 0\n",
    "    for step, data in enumerate(dataloader, 0):\n",
    "        real_imgs, captions, cap_lens, \\\n",
    "                class_ids, keys = prepare_data(data)\n",
    "\n",
    "        words_features, sent_code = cnn_model(real_imgs[-1])\n",
    "        # nef = words_features.size(1)\n",
    "        # words_features = words_features.view(batch_size, nef, -1)\n",
    "\n",
    "        hidden = rnn_model.init_hidden(batch_size)\n",
    "        words_emb, sent_emb = rnn_model(captions, cap_lens, hidden)\n",
    "\n",
    "        w_loss0, w_loss1, attn = words_loss(words_features, words_emb, labels,\n",
    "                                            cap_lens, class_ids, batch_size)\n",
    "        w_total_loss += (w_loss0 + w_loss1).data\n",
    "\n",
    "        s_loss0, s_loss1 = \\\n",
    "            sent_loss(sent_code, sent_emb, labels, class_ids, batch_size)\n",
    "        s_total_loss += (s_loss0 + s_loss1).data\n",
    "\n",
    "        if step == 50:\n",
    "            break\n",
    "\n",
    "    s_cur_loss = s_total_loss / step\n",
    "    w_cur_loss = w_total_loss / step\n",
    "\n",
    "    return s_cur_loss, w_cur_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    # build model ############################################################\n",
    "    text_encoder = RNN_ENCODER(dataset.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\n",
    "    image_encoder = CNN_ENCODER(cfg.TEXT.EMBEDDING_DIM)\n",
    "    labels = Variable(torch.LongTensor(range(batch_size)))\n",
    "    start_epoch = 0\n",
    "    if cfg.TRAIN.NET_E != '':\n",
    "        state_dict = torch.load(cfg.TRAIN.NET_E)\n",
    "        text_encoder.load_state_dict(state_dict)\n",
    "        print('Load ', cfg.TRAIN.NET_E)\n",
    "        #\n",
    "        name = cfg.TRAIN.NET_E.replace('text_encoder', 'image_encoder')\n",
    "        state_dict = torch.load(name)\n",
    "        image_encoder.load_state_dict(state_dict)\n",
    "        print('Load ', name)\n",
    "\n",
    "        istart = cfg.TRAIN.NET_E.rfind('_') + 8\n",
    "        iend = cfg.TRAIN.NET_E.rfind('.')\n",
    "        start_epoch = cfg.TRAIN.NET_E[istart:iend]\n",
    "        start_epoch = int(start_epoch) + 1\n",
    "        print('start_epoch', start_epoch)\n",
    "    if cfg.CUDA:\n",
    "        text_encoder = text_encoder.cuda()\n",
    "        image_encoder = image_encoder.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    return text_encoder, image_encoder, labels, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'B_VALIDATION': False,\n",
      " 'CONFIG_NAME': 'DAMSM',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'coco',\n",
      " 'DATA_DIR': '../data/coco',\n",
      " 'GAN': {'B_ATTENTION': True,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 100,\n",
      "         'DF_DIM': 64,\n",
      "         'GF_DIM': 128,\n",
      "         'R_NUM': 2,\n",
      "         'Z_DIM': 100},\n",
      " 'GPU_ID': 0,\n",
      " 'RNN_TYPE': 'LSTM',\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 15},\n",
      " 'TRAIN': {'BATCH_SIZE': 110,\n",
      "           'B_NET_D': True,\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'ENCODER_LR': 0.0002,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 101,\n",
      "           'NET_E': '',\n",
      "           'NET_G': '',\n",
      "           'RNN_GRAD_CLIP': 0.25,\n",
      "           'SMOOTH': {'GAMMA1': 4.0,\n",
      "                      'GAMMA2': 5.0,\n",
      "                      'GAMMA3': 10.0,\n",
      "                      'LAMBDA': 1.0},\n",
      "           'SNAPSHOT_INTERVAL': 10},\n",
      " 'TREE': {'BASE_SIZE': 299, 'BRANCH_NUM': 1},\n",
      " 'WORKERS': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Jupyter\\meseong\\2020.10.01_10caption_aug\\code\\miscc\\config.py:103: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args #= parse_args()\n",
    "    if args.cfg_file is not None:\n",
    "        cfg_from_file(args.cfg_file)\n",
    "\n",
    "    if args.gpu_id == -1:\n",
    "        cfg.CUDA = False\n",
    "    else:\n",
    "        cfg.GPU_ID = args.gpu_id\n",
    "\n",
    "    if args.data_dir != '':\n",
    "        cfg.DATA_DIR = args.data_dir\n",
    "    print('Using config:')\n",
    "    pprint.pprint(cfg)\n",
    "\n",
    "    if not cfg.TRAIN.FLAG:\n",
    "        args.manualSeed = 100\n",
    "    elif args.manualSeed is None:\n",
    "        args.manualSeed = random.randint(1, 10000)\n",
    "    random.seed(args.manualSeed)\n",
    "    np.random.seed(args.manualSeed)\n",
    "    torch.manual_seed(args.manualSeed)\n",
    "    if cfg.CUDA:\n",
    "        torch.cuda.manual_seed_all(args.manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = '../output/%s_%s_%s' % \\\n",
    "    (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)\n",
    "\n",
    "model_dir = os.path.join(output_dir, 'Model')\n",
    "image_dir = os.path.join(output_dir, 'Image')\n",
    "mkdir_p(model_dir)\n",
    "mkdir_p(image_dir)\n",
    "\n",
    "torch.cuda.set_device(cfg.GPU_ID)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load filenames from: ../data/coco/train/filenames.pickle (82783)\n",
      "Load filenames from: ../data/coco/test/filenames.pickle (40504)\n",
      "Save to:  ../data/coco\\captions.pickle\n",
      "33916 10\n",
      "Load filenames from: ../data/coco/train/filenames.pickle (82783)\n",
      "Load filenames from: ../data/coco/test/filenames.pickle (40504)\n",
      "Load from:  ../data/coco\\captions.pickle\n"
     ]
    }
   ],
   "source": [
    "# Get data loader ##################################################\n",
    "imsize = cfg.TREE.BASE_SIZE * (2 ** (cfg.TREE.BRANCH_NUM-1))\n",
    "batch_size = cfg.TRAIN.BATCH_SIZE\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(int(imsize * 76 / 64)),\n",
    "    transforms.RandomCrop(imsize),\n",
    "    transforms.RandomHorizontalFlip()])\n",
    "dataset = TextDataset(cfg.DATA_DIR, 'train',\n",
    "                      base_size=cfg.TREE.BASE_SIZE,\n",
    "                      transform=image_transform)\n",
    "\n",
    "print(dataset.n_words, dataset.embeddings_num)\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, drop_last=True,\n",
    "    shuffle=True, num_workers=int(cfg.WORKERS))\n",
    "\n",
    "# # validation data #\n",
    "dataset_val = TextDataset(cfg.DATA_DIR, 'test',\n",
    "                          base_size=cfg.TREE.BASE_SIZE,\n",
    "                          transform=image_transform)\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=batch_size, drop_last=True,\n",
    "    shuffle=True, num_workers=int(cfg.WORKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
      "| epoch   0 |     0/  752 batches | ms/batch 49.16 | s_loss  0.02  0.02 | w_loss  0.03  0.03\n",
      "| epoch   0 |   200/  752 batches | ms/batch 4524.48 | s_loss  4.50  4.51 | w_loss  4.64  4.39\n",
      "| epoch   0 |   400/  752 batches | ms/batch 4039.73 | s_loss  3.65  3.62 | w_loss  3.43  3.33\n",
      "| epoch   0 |   600/  752 batches | ms/batch 4344.10 | s_loss  3.16  3.11 | w_loss  2.89  2.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   0 | valid loss  5.09  4.44 | lr 0.00020|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch   1 |     0/  752 batches | ms/batch 15.18 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   1 |   200/  752 batches | ms/batch 3642.48 | s_loss  2.70  2.66 | w_loss  2.45  2.45\n",
      "| epoch   1 |   400/  752 batches | ms/batch 3866.94 | s_loss  2.52  2.48 | w_loss  2.29  2.31\n",
      "| epoch   1 |   600/  752 batches | ms/batch 3657.53 | s_loss  2.37  2.34 | w_loss  2.17  2.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   1 | valid loss  4.03  3.60 | lr 0.00020|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |     0/  752 batches | ms/batch 23.91 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   2 |   200/  752 batches | ms/batch 3921.68 | s_loss  2.19  2.16 | w_loss  2.00  2.04\n",
      "| epoch   2 |   400/  752 batches | ms/batch 3607.56 | s_loss  2.11  2.09 | w_loss  1.93  1.97\n",
      "| epoch   2 |   600/  752 batches | ms/batch 3707.01 | s_loss  2.05  2.03 | w_loss  1.88  1.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   2 | valid loss  3.61  3.26 | lr 0.00019|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |     0/  752 batches | ms/batch 29.23 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   3 |   200/  752 batches | ms/batch 3644.07 | s_loss  1.95  1.93 | w_loss  1.78  1.83\n",
      "| epoch   3 |   400/  752 batches | ms/batch 4955.00 | s_loss  1.91  1.90 | w_loss  1.76  1.81\n",
      "| epoch   3 |   600/  752 batches | ms/batch 4945.94 | s_loss  1.87  1.86 | w_loss  1.70  1.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   3 | valid loss  3.39  3.03 | lr 0.00019|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |     0/  752 batches | ms/batch 15.25 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   4 |   200/  752 batches | ms/batch 5578.21 | s_loss  1.82  1.81 | w_loss  1.65  1.70\n",
      "| epoch   4 |   400/  752 batches | ms/batch 4069.94 | s_loss  1.79  1.78 | w_loss  1.63  1.68\n",
      "| epoch   4 |   600/  752 batches | ms/batch 6325.78 | s_loss  1.78  1.77 | w_loss  1.62  1.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   4 | valid loss  3.23  2.93 | lr 0.00018|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |     0/  752 batches | ms/batch 91.33 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   5 |   200/  752 batches | ms/batch 6445.59 | s_loss  1.72  1.72 | w_loss  1.56  1.61\n",
      "| epoch   5 |   400/  752 batches | ms/batch 7303.23 | s_loss  1.71  1.70 | w_loss  1.54  1.59\n",
      "| epoch   5 |   600/  752 batches | ms/batch 10693.60 | s_loss  1.69  1.69 | w_loss  1.52  1.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   5 | valid loss  3.12  2.77 | lr 0.00018|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |     0/  752 batches | ms/batch 152.65 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   6 |   200/  752 batches | ms/batch 6204.82 | s_loss  1.65  1.65 | w_loss  1.48  1.53\n",
      "| epoch   6 |   400/  752 batches | ms/batch 3774.02 | s_loss  1.64  1.63 | w_loss  1.47  1.51\n",
      "| epoch   6 |   600/  752 batches | ms/batch 3712.53 | s_loss  1.64  1.64 | w_loss  1.47  1.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   6 | valid loss  3.04  2.68 | lr 0.00018|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |     0/  752 batches | ms/batch 14.54 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   7 |   200/  752 batches | ms/batch 3760.49 | s_loss  1.61  1.61 | w_loss  1.43  1.47\n",
      "| epoch   7 |   400/  752 batches | ms/batch 3802.33 | s_loss  1.59  1.58 | w_loss  1.41  1.45\n",
      "| epoch   7 |   600/  752 batches | ms/batch 3742.11 | s_loss  1.59  1.59 | w_loss  1.41  1.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   7 | valid loss  2.94  2.56 | lr 0.00017|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |     0/  752 batches | ms/batch 27.51 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   8 |   200/  752 batches | ms/batch 3872.80 | s_loss  1.55  1.55 | w_loss  1.36  1.41\n",
      "| epoch   8 |   400/  752 batches | ms/batch 3814.28 | s_loss  1.56  1.56 | w_loss  1.38  1.42\n",
      "| epoch   8 |   600/  752 batches | ms/batch 3703.71 | s_loss  1.54  1.54 | w_loss  1.37  1.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   8 | valid loss  2.91  2.56 | lr 0.00017|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |     0/  752 batches | ms/batch 14.69 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   9 |   200/  752 batches | ms/batch 3722.71 | s_loss  1.53  1.53 | w_loss  1.34  1.39\n",
      "| epoch   9 |   400/  752 batches | ms/batch 3981.17 | s_loss  1.51  1.51 | w_loss  1.32  1.36\n",
      "| epoch   9 |   600/  752 batches | ms/batch 3483.00 | s_loss  1.52  1.52 | w_loss  1.34  1.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   9 | valid loss  2.86  2.50 | lr 0.00017|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |     0/  752 batches | ms/batch 14.15 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  10 |   200/  752 batches | ms/batch 3683.92 | s_loss  1.50  1.50 | w_loss  1.32  1.36\n",
      "| epoch  10 |   400/  752 batches | ms/batch 3661.43 | s_loss  1.49  1.49 | w_loss  1.31  1.35\n",
      "| epoch  10 |   600/  752 batches | ms/batch 3705.97 | s_loss  1.50  1.50 | w_loss  1.32  1.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  10 | valid loss  2.82  2.43 | lr 0.00016|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  11 |     0/  752 batches | ms/batch 16.74 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  11 |   200/  752 batches | ms/batch 3798.30 | s_loss  1.46  1.46 | w_loss  1.28  1.31\n",
      "| epoch  11 |   400/  752 batches | ms/batch 3928.87 | s_loss  1.46  1.47 | w_loss  1.27  1.31\n",
      "| epoch  11 |   600/  752 batches | ms/batch 3644.14 | s_loss  1.46  1.46 | w_loss  1.26  1.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  11 | valid loss  2.79  2.44 | lr 0.00016|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |     0/  752 batches | ms/batch 14.47 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  12 |   200/  752 batches | ms/batch 3707.58 | s_loss  1.45  1.45 | w_loss  1.27  1.31\n",
      "| epoch  12 |   400/  752 batches | ms/batch 3860.09 | s_loss  1.44  1.44 | w_loss  1.25  1.29\n",
      "| epoch  12 |   600/  752 batches | ms/batch 3762.24 | s_loss  1.43  1.44 | w_loss  1.24  1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  12 | valid loss  2.75  2.37 | lr 0.00016|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |     0/  752 batches | ms/batch 14.46 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |   200/  752 batches | ms/batch 3852.48 | s_loss  1.42  1.43 | w_loss  1.23  1.27\n",
      "| epoch  13 |   400/  752 batches | ms/batch 3682.09 | s_loss  1.42  1.42 | w_loss  1.23  1.26\n",
      "| epoch  13 |   600/  752 batches | ms/batch 3894.68 | s_loss  1.42  1.43 | w_loss  1.22  1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  13 | valid loss  2.71  2.35 | lr 0.00015|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |     0/  752 batches | ms/batch 21.50 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  14 |   200/  752 batches | ms/batch 3890.91 | s_loss  1.41  1.42 | w_loss  1.21  1.26\n",
      "| epoch  14 |   400/  752 batches | ms/batch 3685.65 | s_loss  1.39  1.40 | w_loss  1.20  1.24\n",
      "| epoch  14 |   600/  752 batches | ms/batch 3827.28 | s_loss  1.41  1.41 | w_loss  1.22  1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  14 | valid loss  2.68  2.29 | lr 0.00015|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |     0/  752 batches | ms/batch 29.32 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  15 |   200/  752 batches | ms/batch 3770.11 | s_loss  1.39  1.39 | w_loss  1.20  1.24\n",
      "| epoch  15 |   400/  752 batches | ms/batch 3822.36 | s_loss  1.39  1.39 | w_loss  1.19  1.23\n",
      "| epoch  15 |   600/  752 batches | ms/batch 3701.91 | s_loss  1.38  1.39 | w_loss  1.17  1.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  15 | valid loss  2.67  2.27 | lr 0.00015|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |     0/  752 batches | ms/batch 14.07 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  16 |   200/  752 batches | ms/batch 3870.34 | s_loss  1.37  1.38 | w_loss  1.17  1.22\n",
      "| epoch  16 |   400/  752 batches | ms/batch 3835.64 | s_loss  1.38  1.39 | w_loss  1.17  1.21\n",
      "| epoch  16 |   600/  752 batches | ms/batch 3796.19 | s_loss  1.36  1.37 | w_loss  1.18  1.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  16 | valid loss  2.68  2.27 | lr 0.00014|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |     0/  752 batches | ms/batch 13.76 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  17 |   200/  752 batches | ms/batch 3787.42 | s_loss  1.35  1.36 | w_loss  1.15  1.19\n",
      "| epoch  17 |   400/  752 batches | ms/batch 3755.74 | s_loss  1.36  1.37 | w_loss  1.16  1.20\n",
      "| epoch  17 |   600/  752 batches | ms/batch 3522.63 | s_loss  1.38  1.39 | w_loss  1.18  1.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  17 | valid loss  2.67  2.29 | lr 0.00014|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |     0/  752 batches | ms/batch 13.84 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  18 |   200/  752 batches | ms/batch 3714.30 | s_loss  1.34  1.35 | w_loss  1.14  1.18\n",
      "| epoch  18 |   400/  752 batches | ms/batch 3901.89 | s_loss  1.34  1.35 | w_loss  1.14  1.18\n",
      "| epoch  18 |   600/  752 batches | ms/batch 3666.54 | s_loss  1.35  1.36 | w_loss  1.14  1.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  18 | valid loss  2.65  2.25 | lr 0.00014|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |     0/  752 batches | ms/batch 14.70 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  19 |   200/  752 batches | ms/batch 3676.85 | s_loss  1.34  1.35 | w_loss  1.13  1.17\n",
      "| epoch  19 |   400/  752 batches | ms/batch 3684.14 | s_loss  1.34  1.35 | w_loss  1.13  1.17\n",
      "| epoch  19 |   600/  752 batches | ms/batch 3697.36 | s_loss  1.35  1.36 | w_loss  1.15  1.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  19 | valid loss  2.61  2.23 | lr 0.00014|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |     0/  752 batches | ms/batch 50.50 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  20 |   200/  752 batches | ms/batch 3681.61 | s_loss  1.32  1.33 | w_loss  1.11  1.15\n",
      "| epoch  20 |   400/  752 batches | ms/batch 3810.58 | s_loss  1.34  1.35 | w_loss  1.13  1.17\n",
      "| epoch  20 |   600/  752 batches | ms/batch 3708.21 | s_loss  1.33  1.34 | w_loss  1.12  1.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  20 | valid loss  2.63  2.23 | lr 0.00013|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  21 |     0/  752 batches | ms/batch 22.82 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  21 |   200/  752 batches | ms/batch 3726.01 | s_loss  1.32  1.33 | w_loss  1.11  1.15\n",
      "| epoch  21 |   400/  752 batches | ms/batch 3700.43 | s_loss  1.32  1.33 | w_loss  1.11  1.16\n",
      "| epoch  21 |   600/  752 batches | ms/batch 3656.07 | s_loss  1.31  1.32 | w_loss  1.10  1.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  21 | valid loss  2.60  2.20 | lr 0.00013|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |     0/  752 batches | ms/batch 14.46 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  22 |   200/  752 batches | ms/batch 3895.71 | s_loss  1.30  1.31 | w_loss  1.08  1.13\n",
      "| epoch  22 |   400/  752 batches | ms/batch 3553.76 | s_loss  1.31  1.32 | w_loss  1.10  1.14\n",
      "| epoch  22 |   600/  752 batches | ms/batch 3921.21 | s_loss  1.32  1.33 | w_loss  1.11  1.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  22 | valid loss  2.56  2.16 | lr 0.00013|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |     0/  752 batches | ms/batch 13.29 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  23 |   200/  752 batches | ms/batch 3725.99 | s_loss  1.30  1.31 | w_loss  1.08  1.12\n",
      "| epoch  23 |   400/  752 batches | ms/batch 3807.99 | s_loss  1.30  1.31 | w_loss  1.10  1.14\n",
      "| epoch  23 |   600/  752 batches | ms/batch 3755.64 | s_loss  1.31  1.32 | w_loss  1.10  1.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  23 | valid loss  2.64  2.23 | lr 0.00013|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |     0/  752 batches | ms/batch 26.35 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  24 |   200/  752 batches | ms/batch 3409.61 | s_loss  1.30  1.32 | w_loss  1.09  1.14\n",
      "| epoch  24 |   400/  752 batches | ms/batch 3699.68 | s_loss  1.30  1.31 | w_loss  1.09  1.13\n",
      "| epoch  24 |   600/  752 batches | ms/batch 3624.96 | s_loss  1.30  1.32 | w_loss  1.09  1.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  24 | valid loss  2.61  2.21 | lr 0.00012|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |     0/  752 batches | ms/batch 15.09 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  25 |   200/  752 batches | ms/batch 3865.37 | s_loss  1.30  1.31 | w_loss  1.09  1.13\n",
      "| epoch  25 |   400/  752 batches | ms/batch 3796.93 | s_loss  1.29  1.30 | w_loss  1.07  1.11\n",
      "| epoch  25 |   600/  752 batches | ms/batch 3711.55 | s_loss  1.30  1.31 | w_loss  1.08  1.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  25 | valid loss  2.58  2.17 | lr 0.00012|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |     0/  752 batches | ms/batch 14.23 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  26 |   200/  752 batches | ms/batch 3669.65 | s_loss  1.28  1.29 | w_loss  1.05  1.09\n",
      "| epoch  26 |   400/  752 batches | ms/batch 3872.69 | s_loss  1.29  1.31 | w_loss  1.08  1.11\n",
      "| epoch  26 |   600/  752 batches | ms/batch 3665.68 | s_loss  1.27  1.28 | w_loss  1.04  1.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  26 | valid loss  2.58  2.17 | lr 0.00012|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |     0/  752 batches | ms/batch 19.31 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  27 |   200/  752 batches | ms/batch 3714.64 | s_loss  1.28  1.29 | w_loss  1.06  1.10\n",
      "| epoch  27 |   400/  752 batches | ms/batch 3761.98 | s_loss  1.28  1.29 | w_loss  1.06  1.10\n",
      "| epoch  27 |   600/  752 batches | ms/batch 3757.66 | s_loss  1.29  1.30 | w_loss  1.06  1.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  27 | valid loss  2.57  2.15 | lr 0.00012|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |     0/  752 batches | ms/batch 14.00 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  28 |   200/  752 batches | ms/batch 3799.86 | s_loss  1.27  1.28 | w_loss  1.04  1.08\n",
      "| epoch  28 |   400/  752 batches | ms/batch 3773.33 | s_loss  1.28  1.29 | w_loss  1.04  1.09\n",
      "| epoch  28 |   600/  752 batches | ms/batch 3554.31 | s_loss  1.26  1.27 | w_loss  1.04  1.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  28 | valid loss  2.58  2.17 | lr 0.00011|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |     0/  752 batches | ms/batch 14.31 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  29 |   200/  752 batches | ms/batch 3913.89 | s_loss  1.27  1.28 | w_loss  1.04  1.09\n",
      "| epoch  29 |   400/  752 batches | ms/batch 3636.46 | s_loss  1.27  1.28 | w_loss  1.06  1.09\n",
      "| epoch  29 |   600/  752 batches | ms/batch 3668.88 | s_loss  1.27  1.28 | w_loss  1.04  1.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  29 | valid loss  2.53  2.12 | lr 0.00011|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |     0/  752 batches | ms/batch 25.95 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  30 |   200/  752 batches | ms/batch 5912.74 | s_loss  1.27  1.28 | w_loss  1.04  1.08\n",
      "| epoch  30 |   400/  752 batches | ms/batch 23067.15 | s_loss  1.26  1.27 | w_loss  1.03  1.07\n",
      "| epoch  30 |   600/  752 batches | ms/batch 20263.46 | s_loss  1.26  1.27 | w_loss  1.03  1.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  30 | valid loss  2.48  2.07 | lr 0.00011|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  31 |     0/  752 batches | ms/batch 15.32 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  31 |   200/  752 batches | ms/batch 3894.89 | s_loss  1.25  1.26 | w_loss  1.02  1.06\n",
      "| epoch  31 |   400/  752 batches | ms/batch 5305.69 | s_loss  1.26  1.27 | w_loss  1.04  1.07\n",
      "| epoch  31 |   600/  752 batches | ms/batch 4522.85 | s_loss  1.26  1.27 | w_loss  1.04  1.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  31 | valid loss  2.53  2.12 | lr 0.00011|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |     0/  752 batches | ms/batch 15.56 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  32 |   200/  752 batches | ms/batch 3662.38 | s_loss  1.25  1.26 | w_loss  1.03  1.08\n",
      "| epoch  32 |   400/  752 batches | ms/batch 3819.90 | s_loss  1.25  1.26 | w_loss  1.01  1.05\n",
      "| epoch  32 |   600/  752 batches | ms/batch 3753.91 | s_loss  1.27  1.28 | w_loss  1.05  1.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  32 | valid loss  2.53  2.08 | lr 0.00010|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |     0/  752 batches | ms/batch 17.44 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  33 |   200/  752 batches | ms/batch 3696.46 | s_loss  1.26  1.27 | w_loss  1.03  1.07\n",
      "| epoch  33 |   400/  752 batches | ms/batch 3788.34 | s_loss  1.24  1.26 | w_loss  1.02  1.06\n",
      "| epoch  33 |   600/  752 batches | ms/batch 3787.52 | s_loss  1.24  1.25 | w_loss  1.01  1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  33 | valid loss  2.51  2.11 | lr 0.00010|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |     0/  752 batches | ms/batch 29.16 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  34 |   200/  752 batches | ms/batch 3698.29 | s_loss  1.25  1.26 | w_loss  1.03  1.07\n",
      "| epoch  34 |   400/  752 batches | ms/batch 3864.13 | s_loss  1.24  1.26 | w_loss  1.01  1.05\n",
      "| epoch  34 |   600/  752 batches | ms/batch 3808.94 | s_loss  1.24  1.25 | w_loss  1.00  1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  34 | valid loss  2.45  2.06 | lr 0.00010|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |     0/  752 batches | ms/batch 13.81 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  35 |   200/  752 batches | ms/batch 3685.08 | s_loss  1.24  1.25 | w_loss  1.01  1.05\n",
      "| epoch  35 |   400/  752 batches | ms/batch 3727.49 | s_loss  1.23  1.24 | w_loss  1.00  1.04\n",
      "| epoch  35 |   600/  752 batches | ms/batch 3796.78 | s_loss  1.25  1.26 | w_loss  1.02  1.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  35 | valid loss  2.56  2.15 | lr 0.00010|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |     0/  752 batches | ms/batch 14.69 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  36 |   200/  752 batches | ms/batch 3661.69 | s_loss  1.23  1.24 | w_loss  1.00  1.04\n",
      "| epoch  36 |   400/  752 batches | ms/batch 3722.52 | s_loss  1.24  1.25 | w_loss  1.00  1.04\n",
      "| epoch  36 |   600/  752 batches | ms/batch 3617.68 | s_loss  1.23  1.24 | w_loss  1.00  1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  36 | valid loss  2.52  2.11 | lr 0.00010|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |     0/  752 batches | ms/batch 14.30 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  37 |   200/  752 batches | ms/batch 3950.71 | s_loss  1.24  1.25 | w_loss  1.01  1.04\n",
      "| epoch  37 |   400/  752 batches | ms/batch 3765.53 | s_loss  1.24  1.25 | w_loss  1.01  1.05\n",
      "| epoch  37 |   600/  752 batches | ms/batch 3871.30 | s_loss  1.24  1.25 | w_loss  1.01  1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  37 | valid loss  2.48  2.05 | lr 0.00009|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |     0/  752 batches | ms/batch 14.77 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  38 |   200/  752 batches | ms/batch 3681.37 | s_loss  1.23  1.24 | w_loss  1.00  1.04\n",
      "| epoch  38 |   400/  752 batches | ms/batch 3705.98 | s_loss  1.22  1.23 | w_loss  0.98  1.02\n",
      "| epoch  38 |   600/  752 batches | ms/batch 3761.42 | s_loss  1.23  1.24 | w_loss  0.99  1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  38 | valid loss  2.48  2.02 | lr 0.00009|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |     0/  752 batches | ms/batch 29.31 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  39 |   200/  752 batches | ms/batch 3695.57 | s_loss  1.22  1.23 | w_loss  0.97  1.01\n",
      "| epoch  39 |   400/  752 batches | ms/batch 3695.25 | s_loss  1.23  1.25 | w_loss  1.00  1.04\n",
      "| epoch  39 |   600/  752 batches | ms/batch 3554.51 | s_loss  1.22  1.23 | w_loss  0.98  1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  39 | valid loss  2.48  2.04 | lr 0.00009|\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  40 |     0/  752 batches | ms/batch 17.12 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  40 |   200/  752 batches | ms/batch 3555.16 | s_loss  1.22  1.23 | w_loss  0.98  1.02\n",
      "| epoch  40 |   400/  752 batches | ms/batch 3444.92 | s_loss  1.22  1.23 | w_loss  0.99  1.03\n",
      "| epoch  40 |   600/  752 batches | ms/batch 3601.93 | s_loss  1.23  1.24 | w_loss  0.99  1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  40 | valid loss  2.47  2.03 | lr 0.00009|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  41 |     0/  752 batches | ms/batch 13.13 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  41 |   200/  752 batches | ms/batch 3633.32 | s_loss  1.22  1.23 | w_loss  0.99  1.02\n",
      "| epoch  41 |   400/  752 batches | ms/batch 3785.35 | s_loss  1.21  1.22 | w_loss  0.97  1.02\n",
      "| epoch  41 |   600/  752 batches | ms/batch 3741.88 | s_loss  1.22  1.24 | w_loss  0.99  1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  41 | valid loss  2.50  2.08 | lr 0.00009|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |     0/  752 batches | ms/batch 14.15 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  42 |   200/  752 batches | ms/batch 3885.14 | s_loss  1.22  1.23 | w_loss  0.97  1.01\n",
      "| epoch  42 |   400/  752 batches | ms/batch 3809.59 | s_loss  1.22  1.23 | w_loss  0.99  1.03\n",
      "| epoch  42 |   600/  752 batches | ms/batch 4035.13 | s_loss  1.22  1.24 | w_loss  0.98  1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  42 | valid loss  2.49  2.08 | lr 0.00009|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |     0/  752 batches | ms/batch 15.23 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  43 |   200/  752 batches | ms/batch 3791.80 | s_loss  1.23  1.25 | w_loss  1.00  1.04\n",
      "| epoch  43 |   400/  752 batches | ms/batch 3539.91 | s_loss  1.23  1.24 | w_loss  1.00  1.04\n",
      "| epoch  43 |   600/  752 batches | ms/batch 3630.00 | s_loss  1.20  1.21 | w_loss  0.97  1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  43 | valid loss  2.50  2.07 | lr 0.00008|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |     0/  752 batches | ms/batch 24.07 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  44 |   200/  752 batches | ms/batch 3612.43 | s_loss  1.21  1.22 | w_loss  0.98  1.02\n",
      "| epoch  44 |   400/  752 batches | ms/batch 3800.54 | s_loss  1.20  1.21 | w_loss  0.96  1.00\n",
      "| epoch  44 |   600/  752 batches | ms/batch 3860.09 | s_loss  1.21  1.23 | w_loss  0.97  1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  44 | valid loss  2.48  2.07 | lr 0.00008|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |     0/  752 batches | ms/batch 15.23 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  45 |   200/  752 batches | ms/batch 3662.78 | s_loss  1.20  1.21 | w_loss  0.96  1.00\n",
      "| epoch  45 |   400/  752 batches | ms/batch 3746.08 | s_loss  1.20  1.21 | w_loss  0.97  1.00\n",
      "| epoch  45 |   600/  752 batches | ms/batch 3703.74 | s_loss  1.21  1.22 | w_loss  0.96  1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  45 | valid loss  2.46  2.04 | lr 0.00008|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |     0/  752 batches | ms/batch 16.42 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  46 |   200/  752 batches | ms/batch 3618.78 | s_loss  1.20  1.21 | w_loss  0.96  1.00\n",
      "| epoch  46 |   400/  752 batches | ms/batch 3839.02 | s_loss  1.20  1.22 | w_loss  0.97  1.01\n",
      "| epoch  46 |   600/  752 batches | ms/batch 3656.42 | s_loss  1.21  1.22 | w_loss  0.97  1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  46 | valid loss  2.45  2.00 | lr 0.00008|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |     0/  752 batches | ms/batch 30.22 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  47 |   200/  752 batches | ms/batch 3786.13 | s_loss  1.22  1.23 | w_loss  0.97  1.01\n",
      "| epoch  47 |   400/  752 batches | ms/batch 3798.37 | s_loss  1.19  1.20 | w_loss  0.95  0.99\n",
      "| epoch  47 |   600/  752 batches | ms/batch 3654.99 | s_loss  1.19  1.21 | w_loss  0.96  1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  47 | valid loss  2.45  2.03 | lr 0.00008|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |     0/  752 batches | ms/batch 22.82 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  48 |   200/  752 batches | ms/batch 3919.95 | s_loss  1.19  1.20 | w_loss  0.95  0.99\n",
      "| epoch  48 |   400/  752 batches | ms/batch 3630.45 | s_loss  1.20  1.21 | w_loss  0.96  1.00\n",
      "| epoch  48 |   600/  752 batches | ms/batch 3678.04 | s_loss  1.20  1.22 | w_loss  0.97  1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  48 | valid loss  2.49  2.07 | lr 0.00008|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |     0/  752 batches | ms/batch 14.85 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  49 |   200/  752 batches | ms/batch 3652.04 | s_loss  1.19  1.20 | w_loss  0.95  1.00\n",
      "| epoch  49 |   400/  752 batches | ms/batch 3729.13 | s_loss  1.19  1.20 | w_loss  0.95  0.99\n",
      "| epoch  49 |   600/  752 batches | ms/batch 3760.14 | s_loss  1.21  1.23 | w_loss  0.98  1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  49 | valid loss  2.45  2.01 | lr 0.00007|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |     0/  752 batches | ms/batch 29.59 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  50 |   200/  752 batches | ms/batch 3793.90 | s_loss  1.19  1.21 | w_loss  0.96  1.00\n",
      "| epoch  50 |   400/  752 batches | ms/batch 3606.28 | s_loss  1.18  1.19 | w_loss  0.94  0.98\n",
      "| epoch  50 |   600/  752 batches | ms/batch 3632.63 | s_loss  1.20  1.22 | w_loss  0.96  1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  50 | valid loss  2.46  2.04 | lr 0.00007|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  51 |     0/  752 batches | ms/batch 14.31 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  51 |   200/  752 batches | ms/batch 3683.76 | s_loss  1.20  1.21 | w_loss  0.95  0.99\n",
      "| epoch  51 |   400/  752 batches | ms/batch 3613.08 | s_loss  1.19  1.21 | w_loss  0.95  0.99\n",
      "| epoch  51 |   600/  752 batches | ms/batch 3776.95 | s_loss  1.19  1.20 | w_loss  0.94  0.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  51 | valid loss  2.45  2.03 | lr 0.00007|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |     0/  752 batches | ms/batch 23.20 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  52 |   200/  752 batches | ms/batch 3743.22 | s_loss  1.18  1.19 | w_loss  0.93  0.97\n",
      "| epoch  52 |   400/  752 batches | ms/batch 3760.49 | s_loss  1.19  1.20 | w_loss  0.94  0.99\n",
      "| epoch  52 |   600/  752 batches | ms/batch 3672.81 | s_loss  1.19  1.21 | w_loss  0.95  0.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  52 | valid loss  2.45  1.99 | lr 0.00007|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |     0/  752 batches | ms/batch 23.68 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  53 |   200/  752 batches | ms/batch 3858.58 | s_loss  1.19  1.20 | w_loss  0.94  0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  53 |   400/  752 batches | ms/batch 3707.10 | s_loss  1.19  1.20 | w_loss  0.94  0.99\n",
      "| epoch  53 |   600/  752 batches | ms/batch 3957.19 | s_loss  1.18  1.19 | w_loss  0.93  0.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  53 | valid loss  2.43  2.01 | lr 0.00007|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |     0/  752 batches | ms/batch 13.60 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  54 |   200/  752 batches | ms/batch 3763.25 | s_loss  1.17  1.19 | w_loss  0.93  0.98\n",
      "| epoch  54 |   400/  752 batches | ms/batch 3842.81 | s_loss  1.20  1.21 | w_loss  0.96  1.00\n",
      "| epoch  54 |   600/  752 batches | ms/batch 3744.07 | s_loss  1.19  1.20 | w_loss  0.94  0.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  54 | valid loss  2.45  2.01 | lr 0.00007|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |     0/  752 batches | ms/batch 16.10 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  55 |   200/  752 batches | ms/batch 3604.52 | s_loss  1.18  1.19 | w_loss  0.94  0.97\n",
      "| epoch  55 |   400/  752 batches | ms/batch 3772.11 | s_loss  1.18  1.19 | w_loss  0.93  0.97\n",
      "| epoch  55 |   600/  752 batches | ms/batch 3567.04 | s_loss  1.17  1.18 | w_loss  0.93  0.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  55 | valid loss  2.45  2.05 | lr 0.00007|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |     0/  752 batches | ms/batch 22.51 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  56 |   200/  752 batches | ms/batch 4753.30 | s_loss  1.17  1.18 | w_loss  0.93  0.96\n",
      "| epoch  56 |   400/  752 batches | ms/batch 5935.33 | s_loss  1.19  1.20 | w_loss  0.94  0.97\n",
      "| epoch  56 |   600/  752 batches | ms/batch 5252.47 | s_loss  1.17  1.19 | w_loss  0.93  0.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  56 | valid loss  2.42  1.96 | lr 0.00006|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 |     0/  752 batches | ms/batch 16.96 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  57 |   200/  752 batches | ms/batch 4044.39 | s_loss  1.17  1.19 | w_loss  0.93  0.97\n",
      "| epoch  57 |   400/  752 batches | ms/batch 6884.86 | s_loss  1.18  1.19 | w_loss  0.94  0.98\n",
      "| epoch  57 |   600/  752 batches | ms/batch 6297.67 | s_loss  1.18  1.20 | w_loss  0.94  0.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  57 | valid loss  2.45  2.01 | lr 0.00006|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |     0/  752 batches | ms/batch 25.73 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  58 |   200/  752 batches | ms/batch 8894.37 | s_loss  1.17  1.19 | w_loss  0.93  0.97\n",
      "| epoch  58 |   400/  752 batches | ms/batch 10710.66 | s_loss  1.18  1.20 | w_loss  0.93  0.97\n",
      "| epoch  58 |   600/  752 batches | ms/batch 10042.27 | s_loss  1.19  1.21 | w_loss  0.94  0.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  58 | valid loss  2.46  2.03 | lr 0.00006|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |     0/  752 batches | ms/batch 15.71 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  59 |   200/  752 batches | ms/batch 3561.23 | s_loss  1.16  1.18 | w_loss  0.92  0.96\n",
      "| epoch  59 |   400/  752 batches | ms/batch 3800.86 | s_loss  1.18  1.19 | w_loss  0.93  0.97\n",
      "| epoch  59 |   600/  752 batches | ms/batch 3845.26 | s_loss  1.19  1.21 | w_loss  0.94  0.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  59 | valid loss  2.44  1.98 | lr 0.00006|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |     0/  752 batches | ms/batch 14.23 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  60 |   200/  752 batches | ms/batch 3704.51 | s_loss  1.19  1.21 | w_loss  0.94  0.98\n",
      "| epoch  60 |   400/  752 batches | ms/batch 3773.04 | s_loss  1.17  1.19 | w_loss  0.94  0.98\n",
      "| epoch  60 |   600/  752 batches | ms/batch 3742.16 | s_loss  1.18  1.19 | w_loss  0.92  0.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  60 | valid loss  2.42  1.98 | lr 0.00006|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  61 |     0/  752 batches | ms/batch 12.66 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  61 |   200/  752 batches | ms/batch 3799.28 | s_loss  1.16  1.17 | w_loss  0.92  0.96\n",
      "| epoch  61 |   400/  752 batches | ms/batch 3670.38 | s_loss  1.18  1.20 | w_loss  0.94  0.98\n",
      "| epoch  61 |   600/  752 batches | ms/batch 3570.18 | s_loss  1.19  1.20 | w_loss  0.94  0.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  61 | valid loss  2.41  1.99 | lr 0.00006|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 |     0/  752 batches | ms/batch 14.85 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  62 |   200/  752 batches | ms/batch 3927.46 | s_loss  1.17  1.19 | w_loss  0.93  0.97\n",
      "| epoch  62 |   400/  752 batches | ms/batch 3712.20 | s_loss  1.18  1.20 | w_loss  0.93  0.97\n",
      "| epoch  62 |   600/  752 batches | ms/batch 3677.49 | s_loss  1.17  1.18 | w_loss  0.92  0.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  62 | valid loss  2.36  1.95 | lr 0.00006|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  63 |     0/  752 batches | ms/batch 19.78 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  63 |   200/  752 batches | ms/batch 3743.90 | s_loss  1.16  1.18 | w_loss  0.92  0.96\n",
      "| epoch  63 |   400/  752 batches | ms/batch 3720.35 | s_loss  1.17  1.18 | w_loss  0.92  0.96\n",
      "| epoch  63 |   600/  752 batches | ms/batch 3667.96 | s_loss  1.18  1.20 | w_loss  0.93  0.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  63 | valid loss  2.44  1.99 | lr 0.00006|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  64 |     0/  752 batches | ms/batch 22.98 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  64 |   200/  752 batches | ms/batch 3846.67 | s_loss  1.15  1.17 | w_loss  0.90  0.95\n",
      "| epoch  64 |   400/  752 batches | ms/batch 3730.20 | s_loss  1.17  1.19 | w_loss  0.93  0.97\n",
      "| epoch  64 |   600/  752 batches | ms/batch 3675.31 | s_loss  1.17  1.18 | w_loss  0.91  0.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  64 | valid loss  2.42  1.98 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  65 |     0/  752 batches | ms/batch 24.79 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  65 |   200/  752 batches | ms/batch 3666.96 | s_loss  1.16  1.18 | w_loss  0.92  0.96\n",
      "| epoch  65 |   400/  752 batches | ms/batch 3646.31 | s_loss  1.17  1.19 | w_loss  0.92  0.96\n",
      "| epoch  65 |   600/  752 batches | ms/batch 3813.07 | s_loss  1.17  1.19 | w_loss  0.92  0.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  65 | valid loss  2.41  1.99 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  66 |     0/  752 batches | ms/batch 14.08 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  66 |   200/  752 batches | ms/batch 3657.34 | s_loss  1.16  1.17 | w_loss  0.92  0.95\n",
      "| epoch  66 |   400/  752 batches | ms/batch 3842.29 | s_loss  1.18  1.19 | w_loss  0.93  0.97\n",
      "| epoch  66 |   600/  752 batches | ms/batch 3498.82 | s_loss  1.16  1.18 | w_loss  0.91  0.95\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| end epoch  66 | valid loss  2.44  2.01 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  67 |     0/  752 batches | ms/batch 15.48 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  67 |   200/  752 batches | ms/batch 3777.23 | s_loss  1.15  1.17 | w_loss  0.91  0.95\n",
      "| epoch  67 |   400/  752 batches | ms/batch 3595.68 | s_loss  1.15  1.16 | w_loss  0.91  0.94\n",
      "| epoch  67 |   600/  752 batches | ms/batch 3904.73 | s_loss  1.16  1.18 | w_loss  0.91  0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  67 | valid loss  2.42  1.99 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  68 |     0/  752 batches | ms/batch 14.23 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  68 |   200/  752 batches | ms/batch 3780.61 | s_loss  1.16  1.18 | w_loss  0.91  0.96\n",
      "| epoch  68 |   400/  752 batches | ms/batch 3767.24 | s_loss  1.16  1.17 | w_loss  0.91  0.95\n",
      "| epoch  68 |   600/  752 batches | ms/batch 3784.14 | s_loss  1.16  1.18 | w_loss  0.91  0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  68 | valid loss  2.41  1.98 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  69 |     0/  752 batches | ms/batch 13.96 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  69 |   200/  752 batches | ms/batch 3774.81 | s_loss  1.17  1.18 | w_loss  0.91  0.95\n",
      "| epoch  69 |   400/  752 batches | ms/batch 3858.33 | s_loss  1.15  1.17 | w_loss  0.91  0.95\n",
      "| epoch  69 |   600/  752 batches | ms/batch 3719.68 | s_loss  1.16  1.17 | w_loss  0.90  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  69 | valid loss  2.47  2.03 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  70 |     0/  752 batches | ms/batch 23.92 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  70 |   200/  752 batches | ms/batch 3765.97 | s_loss  1.16  1.18 | w_loss  0.91  0.95\n",
      "| epoch  70 |   400/  752 batches | ms/batch 3637.22 | s_loss  1.16  1.17 | w_loss  0.90  0.95\n",
      "| epoch  70 |   600/  752 batches | ms/batch 3765.86 | s_loss  1.16  1.17 | w_loss  0.91  0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  70 | valid loss  2.42  1.94 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  71 |     0/  752 batches | ms/batch 14.22 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  71 |   200/  752 batches | ms/batch 3751.54 | s_loss  1.15  1.17 | w_loss  0.91  0.95\n",
      "| epoch  71 |   400/  752 batches | ms/batch 3734.74 | s_loss  1.16  1.18 | w_loss  0.91  0.96\n",
      "| epoch  71 |   600/  752 batches | ms/batch 3798.49 | s_loss  1.15  1.16 | w_loss  0.90  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  71 | valid loss  2.42  1.97 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  72 |     0/  752 batches | ms/batch 14.23 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  72 |   200/  752 batches | ms/batch 3552.64 | s_loss  1.16  1.17 | w_loss  0.91  0.94\n",
      "| epoch  72 |   400/  752 batches | ms/batch 3675.06 | s_loss  1.17  1.19 | w_loss  0.92  0.96\n",
      "| epoch  72 |   600/  752 batches | ms/batch 3908.11 | s_loss  1.15  1.17 | w_loss  0.90  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  72 | valid loss  2.38  1.97 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  73 |     0/  752 batches | ms/batch 12.98 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  73 |   200/  752 batches | ms/batch 3909.73 | s_loss  1.16  1.17 | w_loss  0.91  0.95\n",
      "| epoch  73 |   400/  752 batches | ms/batch 3796.04 | s_loss  1.15  1.17 | w_loss  0.89  0.93\n",
      "| epoch  73 |   600/  752 batches | ms/batch 3775.12 | s_loss  1.15  1.17 | w_loss  0.90  0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  73 | valid loss  2.45  2.00 | lr 0.00005|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  74 |     0/  752 batches | ms/batch 21.73 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  74 |   200/  752 batches | ms/batch 3757.53 | s_loss  1.16  1.18 | w_loss  0.91  0.96\n",
      "| epoch  74 |   400/  752 batches | ms/batch 3908.84 | s_loss  1.16  1.17 | w_loss  0.91  0.95\n",
      "| epoch  74 |   600/  752 batches | ms/batch 3731.50 | s_loss  1.16  1.17 | w_loss  0.90  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  74 | valid loss  2.42  1.99 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  75 |     0/  752 batches | ms/batch 28.61 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  75 |   200/  752 batches | ms/batch 3865.53 | s_loss  1.16  1.18 | w_loss  0.91  0.95\n",
      "| epoch  75 |   400/  752 batches | ms/batch 3782.26 | s_loss  1.15  1.17 | w_loss  0.90  0.95\n",
      "| epoch  75 |   600/  752 batches | ms/batch 3773.80 | s_loss  1.17  1.18 | w_loss  0.92  0.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  75 | valid loss  2.37  1.92 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  76 |     0/  752 batches | ms/batch 13.84 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  76 |   200/  752 batches | ms/batch 3702.62 | s_loss  1.15  1.17 | w_loss  0.91  0.94\n",
      "| epoch  76 |   400/  752 batches | ms/batch 3632.25 | s_loss  1.15  1.17 | w_loss  0.90  0.95\n",
      "| epoch  76 |   600/  752 batches | ms/batch 3716.91 | s_loss  1.15  1.17 | w_loss  0.91  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  76 | valid loss  2.44  2.02 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  77 |     0/  752 batches | ms/batch 14.00 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  77 |   200/  752 batches | ms/batch 3831.35 | s_loss  1.16  1.17 | w_loss  0.90  0.94\n",
      "| epoch  77 |   400/  752 batches | ms/batch 3905.72 | s_loss  1.15  1.17 | w_loss  0.91  0.95\n",
      "| epoch  77 |   600/  752 batches | ms/batch 3883.32 | s_loss  1.15  1.17 | w_loss  0.90  0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  77 | valid loss  2.43  1.97 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  78 |     0/  752 batches | ms/batch 20.40 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  78 |   200/  752 batches | ms/batch 3694.51 | s_loss  1.15  1.16 | w_loss  0.89  0.93\n",
      "| epoch  78 |   400/  752 batches | ms/batch 3641.06 | s_loss  1.14  1.16 | w_loss  0.89  0.93\n",
      "| epoch  78 |   600/  752 batches | ms/batch 3652.66 | s_loss  1.15  1.16 | w_loss  0.89  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  78 | valid loss  2.39  1.99 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  79 |     0/  752 batches | ms/batch 14.15 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  79 |   200/  752 batches | ms/batch 4005.30 | s_loss  1.15  1.16 | w_loss  0.90  0.94\n",
      "| epoch  79 |   400/  752 batches | ms/batch 3741.43 | s_loss  1.15  1.17 | w_loss  0.91  0.95\n",
      "| epoch  79 |   600/  752 batches | ms/batch 3781.92 | s_loss  1.15  1.17 | w_loss  0.90  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  79 | valid loss  2.40  1.96 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  80 |     0/  752 batches | ms/batch 15.25 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  80 |   200/  752 batches | ms/batch 3704.40 | s_loss  1.15  1.16 | w_loss  0.90  0.94\n",
      "| epoch  80 |   400/  752 batches | ms/batch 3705.37 | s_loss  1.14  1.16 | w_loss  0.89  0.93\n",
      "| epoch  80 |   600/  752 batches | ms/batch 3712.01 | s_loss  1.16  1.18 | w_loss  0.90  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  80 | valid loss  2.40  1.96 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  81 |     0/  752 batches | ms/batch 13.67 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  81 |   200/  752 batches | ms/batch 3713.65 | s_loss  1.15  1.17 | w_loss  0.90  0.94\n",
      "| epoch  81 |   400/  752 batches | ms/batch 3961.78 | s_loss  1.14  1.15 | w_loss  0.89  0.93\n",
      "| epoch  81 |   600/  752 batches | ms/batch 3740.76 | s_loss  1.15  1.17 | w_loss  0.91  0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  81 | valid loss  2.38  1.92 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  82 |     0/  752 batches | ms/batch 28.37 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  82 |   200/  752 batches | ms/batch 3830.83 | s_loss  1.15  1.16 | w_loss  0.90  0.94\n",
      "| epoch  82 |   400/  752 batches | ms/batch 3615.90 | s_loss  1.14  1.15 | w_loss  0.89  0.92\n",
      "| epoch  82 |   600/  752 batches | ms/batch 3793.32 | s_loss  1.15  1.16 | w_loss  0.89  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  82 | valid loss  2.41  1.99 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  83 |     0/  752 batches | ms/batch 17.13 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  83 |   200/  752 batches | ms/batch 4254.44 | s_loss  1.14  1.15 | w_loss  0.89  0.94\n",
      "| epoch  83 |   400/  752 batches | ms/batch 4547.17 | s_loss  1.15  1.17 | w_loss  0.90  0.94\n",
      "| epoch  83 |   600/  752 batches | ms/batch 4495.99 | s_loss  1.14  1.16 | w_loss  0.90  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  83 | valid loss  2.42  2.00 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  84 |     0/  752 batches | ms/batch 27.05 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  84 |   200/  752 batches | ms/batch 4613.43 | s_loss  1.15  1.16 | w_loss  0.89  0.93\n",
      "| epoch  84 |   400/  752 batches | ms/batch 4466.06 | s_loss  1.14  1.16 | w_loss  0.89  0.94\n",
      "| epoch  84 |   600/  752 batches | ms/batch 4340.82 | s_loss  1.13  1.15 | w_loss  0.87  0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  84 | valid loss  2.44  2.00 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  85 |     0/  752 batches | ms/batch 23.76 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  85 |   200/  752 batches | ms/batch 4489.49 | s_loss  1.16  1.17 | w_loss  0.91  0.95\n",
      "| epoch  85 |   400/  752 batches | ms/batch 4386.21 | s_loss  1.14  1.15 | w_loss  0.88  0.93\n",
      "| epoch  85 |   600/  752 batches | ms/batch 4504.53 | s_loss  1.13  1.15 | w_loss  0.87  0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  85 | valid loss  2.40  1.96 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  86 |     0/  752 batches | ms/batch 27.36 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  86 |   200/  752 batches | ms/batch 4538.84 | s_loss  1.15  1.16 | w_loss  0.89  0.93\n",
      "| epoch  86 |   400/  752 batches | ms/batch 4142.22 | s_loss  1.14  1.15 | w_loss  0.88  0.92\n",
      "| epoch  86 |   600/  752 batches | ms/batch 4263.77 | s_loss  1.15  1.17 | w_loss  0.89  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  86 | valid loss  2.38  1.93 | lr 0.00004|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  87 |     0/  752 batches | ms/batch 14.93 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  87 |   200/  752 batches | ms/batch 3767.30 | s_loss  1.16  1.17 | w_loss  0.90  0.94\n",
      "| epoch  87 |   400/  752 batches | ms/batch 3577.72 | s_loss  1.15  1.17 | w_loss  0.89  0.94\n",
      "| epoch  87 |   600/  752 batches | ms/batch 3661.06 | s_loss  1.14  1.16 | w_loss  0.88  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  87 | valid loss  2.38  1.92 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  88 |     0/  752 batches | ms/batch 14.39 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  88 |   200/  752 batches | ms/batch 3777.35 | s_loss  1.14  1.15 | w_loss  0.89  0.93\n",
      "| epoch  88 |   400/  752 batches | ms/batch 3707.42 | s_loss  1.14  1.16 | w_loss  0.88  0.92\n",
      "| epoch  88 |   600/  752 batches | ms/batch 3756.18 | s_loss  1.14  1.16 | w_loss  0.89  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  88 | valid loss  2.44  2.00 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  89 |     0/  752 batches | ms/batch 14.63 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  89 |   200/  752 batches | ms/batch 3743.78 | s_loss  1.14  1.15 | w_loss  0.88  0.92\n",
      "| epoch  89 |   400/  752 batches | ms/batch 3898.72 | s_loss  1.14  1.15 | w_loss  0.88  0.92\n",
      "| epoch  89 |   600/  752 batches | ms/batch 3720.86 | s_loss  1.13  1.14 | w_loss  0.88  0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  89 | valid loss  2.40  1.96 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  90 |     0/  752 batches | ms/batch 14.54 | s_loss  0.01  0.01 | w_loss  0.01  0.00\n",
      "| epoch  90 |   200/  752 batches | ms/batch 3836.55 | s_loss  1.14  1.15 | w_loss  0.88  0.92\n",
      "| epoch  90 |   400/  752 batches | ms/batch 3567.79 | s_loss  1.15  1.16 | w_loss  0.90  0.93\n",
      "| epoch  90 |   600/  752 batches | ms/batch 3923.86 | s_loss  1.14  1.15 | w_loss  0.88  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  90 | valid loss  2.39  1.99 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  91 |     0/  752 batches | ms/batch 17.66 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  91 |   200/  752 batches | ms/batch 3534.85 | s_loss  1.14  1.15 | w_loss  0.88  0.93\n",
      "| epoch  91 |   400/  752 batches | ms/batch 3756.64 | s_loss  1.13  1.14 | w_loss  0.88  0.91\n",
      "| epoch  91 |   600/  752 batches | ms/batch 3778.27 | s_loss  1.15  1.17 | w_loss  0.90  0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  91 | valid loss  2.38  1.95 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  92 |     0/  752 batches | ms/batch 13.60 | s_loss  0.00  0.01 | w_loss  0.00  0.00\n",
      "| epoch  92 |   200/  752 batches | ms/batch 3751.44 | s_loss  1.14  1.16 | w_loss  0.89  0.93\n",
      "| epoch  92 |   400/  752 batches | ms/batch 3789.60 | s_loss  1.13  1.15 | w_loss  0.88  0.92\n",
      "| epoch  92 |   600/  752 batches | ms/batch 3558.28 | s_loss  1.14  1.15 | w_loss  0.88  0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  92 | valid loss  2.42  1.97 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  93 |     0/  752 batches | ms/batch 15.24 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  93 |   200/  752 batches | ms/batch 3796.23 | s_loss  1.13  1.15 | w_loss  0.87  0.91\n",
      "| epoch  93 |   400/  752 batches | ms/batch 3804.17 | s_loss  1.15  1.16 | w_loss  0.90  0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  93 |   600/  752 batches | ms/batch 3751.30 | s_loss  1.15  1.16 | w_loss  0.89  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  93 | valid loss  2.39  1.94 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  94 |     0/  752 batches | ms/batch 14.69 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  94 |   200/  752 batches | ms/batch 3768.92 | s_loss  1.13  1.15 | w_loss  0.88  0.92\n",
      "| epoch  94 |   400/  752 batches | ms/batch 3571.70 | s_loss  1.14  1.16 | w_loss  0.89  0.93\n",
      "| epoch  94 |   600/  752 batches | ms/batch 3711.72 | s_loss  1.15  1.16 | w_loss  0.89  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  94 | valid loss  2.37  1.92 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  95 |     0/  752 batches | ms/batch 13.36 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  95 |   200/  752 batches | ms/batch 3751.19 | s_loss  1.14  1.16 | w_loss  0.89  0.93\n",
      "| epoch  95 |   400/  752 batches | ms/batch 3813.73 | s_loss  1.15  1.16 | w_loss  0.89  0.93\n",
      "| epoch  95 |   600/  752 batches | ms/batch 3823.69 | s_loss  1.14  1.15 | w_loss  0.89  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  95 | valid loss  2.36  1.93 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  96 |     0/  752 batches | ms/batch 32.35 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch  96 |   200/  752 batches | ms/batch 3663.65 | s_loss  1.13  1.15 | w_loss  0.88  0.92\n",
      "| epoch  96 |   400/  752 batches | ms/batch 3521.23 | s_loss  1.14  1.15 | w_loss  0.88  0.92\n",
      "| epoch  96 |   600/  752 batches | ms/batch 3626.46 | s_loss  1.14  1.15 | w_loss  0.88  0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  96 | valid loss  2.32  1.88 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  97 |     0/  752 batches | ms/batch 14.92 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  97 |   200/  752 batches | ms/batch 3963.32 | s_loss  1.14  1.16 | w_loss  0.88  0.93\n",
      "| epoch  97 |   400/  752 batches | ms/batch 3702.19 | s_loss  1.13  1.14 | w_loss  0.87  0.92\n",
      "| epoch  97 |   600/  752 batches | ms/batch 3892.11 | s_loss  1.13  1.15 | w_loss  0.88  0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  97 | valid loss  2.41  1.94 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  98 |     0/  752 batches | ms/batch 18.05 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  98 |   200/  752 batches | ms/batch 3679.00 | s_loss  1.13  1.15 | w_loss  0.87  0.91\n",
      "| epoch  98 |   400/  752 batches | ms/batch 3735.37 | s_loss  1.13  1.15 | w_loss  0.88  0.92\n",
      "| epoch  98 |   600/  752 batches | ms/batch 3580.72 | s_loss  1.13  1.14 | w_loss  0.86  0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  98 | valid loss  2.43  1.98 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  99 |     0/  752 batches | ms/batch 14.46 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  99 |   200/  752 batches | ms/batch 3583.16 | s_loss  1.14  1.15 | w_loss  0.88  0.92\n",
      "| epoch  99 |   400/  752 batches | ms/batch 3532.95 | s_loss  1.14  1.16 | w_loss  0.88  0.92\n",
      "| epoch  99 |   600/  752 batches | ms/batch 3766.94 | s_loss  1.14  1.15 | w_loss  0.87  0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  99 | valid loss  2.38  1.93 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 100 |     0/  752 batches | ms/batch 14.30 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch 100 |   200/  752 batches | ms/batch 3637.99 | s_loss  1.14  1.16 | w_loss  0.89  0.93\n",
      "| epoch 100 |   400/  752 batches | ms/batch 3775.62 | s_loss  1.13  1.15 | w_loss  0.88  0.92\n",
      "| epoch 100 |   600/  752 batches | ms/batch 3712.56 | s_loss  1.13  1.15 | w_loss  0.87  0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch 100 | valid loss  2.39  1.97 | lr 0.00003|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n"
     ]
    }
   ],
   "source": [
    "# Train ##############################################################\n",
    "text_encoder, image_encoder, labels, start_epoch = build_models()\n",
    "para = list(text_encoder.parameters())\n",
    "for v in image_encoder.parameters():\n",
    "    if v.requires_grad:\n",
    "        para.append(v)\n",
    "# optimizer = optim.Adam(para, lr=cfg.TRAIN.ENCODER_LR, betas=(0.5, 0.999))\n",
    "# At any point you can hit Ctrl + C to break out of training early.\n",
    "try:\n",
    "    lr = cfg.TRAIN.ENCODER_LR\n",
    "    for epoch in range(start_epoch, cfg.TRAIN.MAX_EPOCH):\n",
    "        optimizer = optim.Adam(para, lr=lr, betas=(0.5, 0.999))\n",
    "        epoch_start_time = time.time()\n",
    "        count = train(dataloader, image_encoder, text_encoder,\n",
    "                      batch_size, labels, optimizer, epoch,\n",
    "                      dataset.ixtoword, image_dir)\n",
    "        print('-' * 89)\n",
    "        if len(dataloader_val) > 0:\n",
    "            s_loss, w_loss = evaluate(dataloader_val, image_encoder,\n",
    "                                      text_encoder, batch_size)\n",
    "            print('| end epoch {:3d} | valid loss '\n",
    "                  '{:5.2f} {:5.2f} | lr {:.5f}|'\n",
    "                  .format(epoch, s_loss, w_loss, lr))\n",
    "        print('-' * 89)\n",
    "        if lr > cfg.TRAIN.ENCODER_LR/10.:\n",
    "            lr *= 0.98\n",
    "\n",
    "        if (epoch % cfg.TRAIN.SNAPSHOT_INTERVAL == 0 or\n",
    "            epoch == cfg.TRAIN.MAX_EPOCH):\n",
    "            torch.save(image_encoder.state_dict(),\n",
    "                       '%s/image_encoder%d.pth' % (model_dir, epoch))\n",
    "            torch.save(text_encoder.state_dict(),\n",
    "                       '%s/text_encoder%d.pth' % (model_dir, epoch))\n",
    "            print('Save G/Ds models.')\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_torchgan)",
   "language": "python",
   "name": "conda_torchgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
